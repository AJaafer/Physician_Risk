{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import roc_auc_score as auc \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/X_train_test_CombinedCategories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "df1 = df.groupby('Provider Type').transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "train_x = df1.iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.0005\n",
    "training_epochs = 150\n",
    "batch_size = 1024\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 15 # 1st layer num features\n",
    "#n_hidden_2 = 15 # 2nd layer num features\n",
    "n_input = train_x.shape[1] # MNIST data input (img shape: 28*28)\n",
    "data_dir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 1.811736584 Time elapsed= 0:00:01.469811\n",
      "Epoch: 0002 cost= 1.437579751 Time elapsed= 0:00:01.566980\n",
      "Epoch: 0003 cost= 1.577134252 Time elapsed= 0:00:01.668857\n",
      "Epoch: 0004 cost= 1.493493438 Time elapsed= 0:00:01.792512\n",
      "Epoch: 0005 cost= 1.607101679 Time elapsed= 0:00:01.891868\n",
      "Epoch: 0006 cost= 1.266075373 Time elapsed= 0:00:01.991523\n",
      "Epoch: 0007 cost= 1.460443974 Time elapsed= 0:00:02.110778\n",
      "Epoch: 0008 cost= 1.628917456 Time elapsed= 0:00:02.213614\n",
      "Epoch: 0009 cost= 1.466831923 Time elapsed= 0:00:02.308199\n",
      "Epoch: 0010 cost= 2.039290667 Time elapsed= 0:00:02.439697\n",
      "Epoch: 0011 cost= 1.279381633 Time elapsed= 0:00:02.538905\n",
      "Epoch: 0012 cost= 1.488589883 Time elapsed= 0:00:02.635941\n",
      "Epoch: 0013 cost= 1.229589343 Time elapsed= 0:00:02.758672\n",
      "Epoch: 0014 cost= 1.159185767 Time elapsed= 0:00:02.868372\n",
      "Epoch: 0015 cost= 1.208297849 Time elapsed= 0:00:02.991187\n",
      "Epoch: 0016 cost= 1.242755175 Time elapsed= 0:00:03.101496\n",
      "Epoch: 0017 cost= 1.608197808 Time elapsed= 0:00:03.202152\n",
      "Epoch: 0018 cost= 1.500871301 Time elapsed= 0:00:03.326227\n",
      "Epoch: 0019 cost= 1.192386985 Time elapsed= 0:00:03.437898\n",
      "Epoch: 0020 cost= 0.939300299 Time elapsed= 0:00:03.550811\n",
      "Epoch: 0021 cost= 1.236491323 Time elapsed= 0:00:03.654098\n",
      "Epoch: 0022 cost= 1.161283851 Time elapsed= 0:00:03.829324\n",
      "Epoch: 0023 cost= 1.373608351 Time elapsed= 0:00:04.128251\n",
      "Epoch: 0024 cost= 1.150023341 Time elapsed= 0:00:04.245024\n",
      "Epoch: 0025 cost= 0.933834255 Time elapsed= 0:00:04.345878\n",
      "Epoch: 0026 cost= 1.182100177 Time elapsed= 0:00:04.473074\n",
      "Epoch: 0027 cost= 1.255448341 Time elapsed= 0:00:04.575059\n",
      "Epoch: 0028 cost= 1.313301206 Time elapsed= 0:00:04.696612\n",
      "Epoch: 0029 cost= 1.114004016 Time elapsed= 0:00:04.792553\n",
      "Epoch: 0030 cost= 1.261304259 Time elapsed= 0:00:04.912993\n",
      "Epoch: 0031 cost= 1.526661634 Time elapsed= 0:00:05.011248\n",
      "Epoch: 0032 cost= 1.099889874 Time elapsed= 0:00:05.125934\n",
      "Epoch: 0033 cost= 0.874347150 Time elapsed= 0:00:05.227369\n",
      "Epoch: 0034 cost= 0.988218784 Time elapsed= 0:00:05.349236\n",
      "Epoch: 0035 cost= 0.968322635 Time elapsed= 0:00:05.450779\n",
      "Epoch: 0036 cost= 0.826588869 Time elapsed= 0:00:05.566069\n",
      "Epoch: 0037 cost= 1.432167411 Time elapsed= 0:00:05.667276\n",
      "Epoch: 0038 cost= 1.173700571 Time elapsed= 0:00:05.788282\n",
      "Epoch: 0039 cost= 1.016906619 Time elapsed= 0:00:06.000093\n",
      "Epoch: 0040 cost= 1.025571465 Time elapsed= 0:00:06.190837\n",
      "Epoch: 0041 cost= 1.035729289 Time elapsed= 0:00:06.311241\n",
      "Epoch: 0042 cost= 0.823040724 Time elapsed= 0:00:06.421415\n",
      "Epoch: 0043 cost= 0.871152520 Time elapsed= 0:00:06.531895\n",
      "Epoch: 0044 cost= 0.801167428 Time elapsed= 0:00:06.668909\n",
      "Epoch: 0045 cost= 0.799840987 Time elapsed= 0:00:06.829115\n",
      "Epoch: 0046 cost= 0.756193757 Time elapsed= 0:00:06.949950\n",
      "Epoch: 0047 cost= 0.772619963 Time elapsed= 0:00:07.071974\n",
      "Epoch: 0048 cost= 0.786846578 Time elapsed= 0:00:07.209972\n",
      "Epoch: 0049 cost= 0.879628122 Time elapsed= 0:00:07.330637\n",
      "Epoch: 0050 cost= 0.828284204 Time elapsed= 0:00:07.460820\n",
      "Epoch: 0051 cost= 0.940948606 Time elapsed= 0:00:07.605441\n",
      "Epoch: 0052 cost= 0.765339732 Time elapsed= 0:00:07.721168\n",
      "Epoch: 0053 cost= 0.776748061 Time elapsed= 0:00:07.829080\n",
      "Epoch: 0054 cost= 0.881351471 Time elapsed= 0:00:07.964393\n",
      "Epoch: 0055 cost= 0.920028269 Time elapsed= 0:00:08.092936\n",
      "Epoch: 0056 cost= 0.797007620 Time elapsed= 0:00:08.211591\n",
      "Epoch: 0057 cost= 0.797395468 Time elapsed= 0:00:08.342223\n",
      "Epoch: 0058 cost= 0.651628733 Time elapsed= 0:00:08.474913\n",
      "Epoch: 0059 cost= 0.807693899 Time elapsed= 0:00:08.635376\n",
      "Epoch: 0060 cost= 0.842975080 Time elapsed= 0:00:08.893332\n",
      "Epoch: 0061 cost= 0.764299452 Time elapsed= 0:00:09.034641\n",
      "Epoch: 0062 cost= 1.087867022 Time elapsed= 0:00:09.164812\n",
      "Epoch: 0063 cost= 0.631797433 Time elapsed= 0:00:09.283687\n",
      "Epoch: 0064 cost= 1.309253931 Time elapsed= 0:00:09.407566\n",
      "Epoch: 0065 cost= 0.698955357 Time elapsed= 0:00:09.538709\n",
      "Epoch: 0066 cost= 0.975718558 Time elapsed= 0:00:09.664802\n",
      "Epoch: 0067 cost= 0.726727843 Time elapsed= 0:00:09.780760\n",
      "Epoch: 0068 cost= 1.091850638 Time elapsed= 0:00:09.900531\n",
      "Epoch: 0069 cost= 0.908089757 Time elapsed= 0:00:10.031928\n",
      "Epoch: 0070 cost= 1.143018126 Time elapsed= 0:00:10.145332\n",
      "Epoch: 0071 cost= 0.929143846 Time elapsed= 0:00:10.275869\n",
      "Epoch: 0072 cost= 0.929117978 Time elapsed= 0:00:10.408656\n",
      "Epoch: 0073 cost= 0.716081500 Time elapsed= 0:00:10.716783\n",
      "Epoch: 0074 cost= 1.045226574 Time elapsed= 0:00:10.845357\n",
      "Epoch: 0075 cost= 0.591906428 Time elapsed= 0:00:10.967255\n",
      "Epoch: 0076 cost= 0.838710666 Time elapsed= 0:00:11.092081\n",
      "Epoch: 0077 cost= 0.591671467 Time elapsed= 0:00:11.218681\n",
      "Epoch: 0078 cost= 0.579102397 Time elapsed= 0:00:11.340562\n",
      "Epoch: 0079 cost= 0.758261263 Time elapsed= 0:00:11.475326\n",
      "Epoch: 0080 cost= 0.800182104 Time elapsed= 0:00:11.603757\n",
      "Epoch: 0081 cost= 0.894027531 Time elapsed= 0:00:11.765725\n",
      "Epoch: 0082 cost= 0.744028926 Time elapsed= 0:00:11.886759\n",
      "Epoch: 0083 cost= 0.676729381 Time elapsed= 0:00:12.017146\n",
      "Epoch: 0084 cost= 0.841363490 Time elapsed= 0:00:12.139849\n",
      "Epoch: 0085 cost= 0.726012170 Time elapsed= 0:00:12.266302\n",
      "Epoch: 0086 cost= 0.661610782 Time elapsed= 0:00:12.391047\n",
      "Epoch: 0087 cost= 0.559495270 Time elapsed= 0:00:12.515809\n",
      "Epoch: 0088 cost= 0.804105937 Time elapsed= 0:00:12.635853\n",
      "Epoch: 0089 cost= 0.936248124 Time elapsed= 0:00:12.760511\n",
      "Epoch: 0090 cost= 0.708231449 Time elapsed= 0:00:12.885673\n",
      "Epoch: 0091 cost= 0.518715143 Time elapsed= 0:00:13.009474\n",
      "Epoch: 0092 cost= 0.634905219 Time elapsed= 0:00:13.132027\n",
      "Epoch: 0093 cost= 0.706253171 Time elapsed= 0:00:13.279016\n",
      "Epoch: 0094 cost= 0.674420297 Time elapsed= 0:00:13.542119\n",
      "Epoch: 0095 cost= 0.855423808 Time elapsed= 0:00:13.713871\n",
      "Epoch: 0096 cost= 0.580287337 Time elapsed= 0:00:13.854352\n",
      "Epoch: 0097 cost= 1.069505930 Time elapsed= 0:00:13.969782\n",
      "Epoch: 0098 cost= 0.642120957 Time elapsed= 0:00:14.093485\n",
      "Epoch: 0099 cost= 0.839036822 Time elapsed= 0:00:14.228956\n",
      "Epoch: 0100 cost= 0.657487273 Time elapsed= 0:00:14.372106\n",
      "Epoch: 0101 cost= 0.575495481 Time elapsed= 0:00:14.560652\n",
      "Epoch: 0102 cost= 0.639277637 Time elapsed= 0:00:14.766663\n",
      "Epoch: 0103 cost= 0.812190533 Time elapsed= 0:00:14.882810\n",
      "Epoch: 0104 cost= 0.601157248 Time elapsed= 0:00:15.007361\n",
      "Epoch: 0105 cost= 0.531888604 Time elapsed= 0:00:15.137143\n",
      "Epoch: 0106 cost= 0.681726456 Time elapsed= 0:00:15.273020\n",
      "Epoch: 0107 cost= 0.596634567 Time elapsed= 0:00:15.399517\n",
      "Epoch: 0108 cost= 0.679277480 Time elapsed= 0:00:15.529927\n",
      "Epoch: 0109 cost= 0.530492365 Time elapsed= 0:00:15.661678\n",
      "Epoch: 0110 cost= 0.550195992 Time elapsed= 0:00:15.794505\n",
      "Epoch: 0111 cost= 0.444980592 Time elapsed= 0:00:15.907646\n",
      "Epoch: 0112 cost= 0.501664758 Time elapsed= 0:00:16.079602\n",
      "Epoch: 0113 cost= 0.786004782 Time elapsed= 0:00:16.251617\n",
      "Epoch: 0114 cost= 0.624769926 Time elapsed= 0:00:16.378594\n",
      "Epoch: 0115 cost= 0.500298142 Time elapsed= 0:00:16.520642\n",
      "Epoch: 0116 cost= 0.460895598 Time elapsed= 0:00:16.860155\n",
      "Epoch: 0117 cost= 0.425105661 Time elapsed= 0:00:17.077084\n",
      "Epoch: 0118 cost= 0.412595421 Time elapsed= 0:00:17.310439\n",
      "Epoch: 0119 cost= 0.525488257 Time elapsed= 0:00:17.542315\n",
      "Epoch: 0120 cost= 0.784848034 Time elapsed= 0:00:17.689198\n",
      "Epoch: 0121 cost= 0.601731479 Time elapsed= 0:00:17.925678\n",
      "Epoch: 0122 cost= 0.552321613 Time elapsed= 0:00:18.122116\n",
      "Epoch: 0123 cost= 0.427933007 Time elapsed= 0:00:18.314623\n",
      "Epoch: 0124 cost= 0.653327227 Time elapsed= 0:00:18.465545\n",
      "Epoch: 0125 cost= 0.753524363 Time elapsed= 0:00:18.761697\n",
      "Epoch: 0126 cost= 0.485186338 Time elapsed= 0:00:18.937853\n",
      "Epoch: 0127 cost= 0.592441320 Time elapsed= 0:00:19.116501\n",
      "Epoch: 0128 cost= 0.623123288 Time elapsed= 0:00:19.333844\n",
      "Epoch: 0129 cost= 0.586566389 Time elapsed= 0:00:19.495479\n",
      "Epoch: 0130 cost= 0.792209506 Time elapsed= 0:00:19.690718\n",
      "Epoch: 0131 cost= 0.539297640 Time elapsed= 0:00:19.825173\n",
      "Epoch: 0132 cost= 0.990557432 Time elapsed= 0:00:19.964273\n",
      "Epoch: 0133 cost= 0.458832502 Time elapsed= 0:00:20.105605\n",
      "Epoch: 0134 cost= 0.616836905 Time elapsed= 0:00:20.407771\n",
      "Epoch: 0135 cost= 0.484814286 Time elapsed= 0:00:20.578057\n",
      "Epoch: 0136 cost= 0.750165105 Time elapsed= 0:00:20.723108\n",
      "Epoch: 0137 cost= 0.650462985 Time elapsed= 0:00:20.837388\n",
      "Epoch: 0138 cost= 1.045011759 Time elapsed= 0:00:20.971010\n",
      "Epoch: 0139 cost= 0.392018855 Time elapsed= 0:00:21.095381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0140 cost= 0.635331213 Time elapsed= 0:00:21.205321\n",
      "Epoch: 0141 cost= 0.446963012 Time elapsed= 0:00:21.402580\n",
      "Epoch: 0142 cost= 0.384331077 Time elapsed= 0:00:21.680574\n",
      "Epoch: 0143 cost= 0.592375457 Time elapsed= 0:00:21.981738\n",
      "Epoch: 0144 cost= 0.391087890 Time elapsed= 0:00:22.137574\n",
      "Epoch: 0145 cost= 0.428010404 Time elapsed= 0:00:22.273089\n",
      "Epoch: 0146 cost= 0.559345841 Time elapsed= 0:00:22.390846\n",
      "Epoch: 0147 cost= 0.446429968 Time elapsed= 0:00:22.577581\n",
      "Epoch: 0148 cost= 0.448860705 Time elapsed= 0:00:22.701249\n",
      "Epoch: 0149 cost= 0.802969456 Time elapsed= 0:00:22.819220\n",
      "Epoch: 0150 cost= 0.373167038 Time elapsed= 0:00:22.949936\n",
      "Optimization Finished!\n",
      "Model saved in file: ./temp_saved_model_1layer.ckpt\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    #'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "    #'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    #'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([n_input])),\n",
    "    #'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n",
    "}\n",
    "\n",
    "\n",
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                   biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    #layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                   #biases['encoder_b2']))\n",
    "    return layer_1\n",
    "\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                   biases['decoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    #layer_2 = tf.nn.tanh(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                  # biases['decoder_b2']))\n",
    "    return layer_1\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "# Targets (Labels) are the input data.\n",
    "y_true = X\n",
    "\n",
    "# Define batch mse\n",
    "batch_mse = tf.reduce_mean(tf.pow(y_true - y_pred, 2), 1)\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# TRAIN StARTS\n",
    "save_model = os.path.join(data_dir, 'temp_saved_model_1layer.ckpt')\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    now = datetime.now()\n",
    "    sess.run(init)\n",
    "    total_batch = int(train_x.shape[0]/batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_idx = np.random.choice(train_x.shape[0], batch_size)\n",
    "            batch_xs = train_x[batch_idx]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
    "        \n",
    "        \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            train_batch_mse = sess.run(batch_mse, feed_dict={X: train_x})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1),\n",
    "                  \"cost=\", \"{:.9f}\".format(c), \n",
    "                  #\"Train auc=\", \"{:.6f}\".format(auc(train_y, train_batch_mse)), \n",
    "                  \"Time elapsed=\", \"{}\".format(datetime.now() - now))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    save_path = saver.save(sess, save_model)\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./temp_saved_model_1layer.ckpt\n"
     ]
    }
   ],
   "source": [
    "save_model = os.path.join(data_dir, 'temp_saved_model_1layer.ckpt')\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    now = datetime.now()\n",
    "    \n",
    "    saver.restore(sess, save_model)\n",
    "    \n",
    "    train_batch_mse = sess.run(batch_mse, feed_dict={X: train_x})\n",
    "    \n",
    "    #print(\"Test auc score: {:.6f}\".format(auc(test_y, test_batch_mse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf1RUkXD1DrPgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f556e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_batch_mse[(train_batch_mse < 5)], bins = 100)\n",
    "plt.title(\"fraud score (mse) distribution\")\n",
    "plt.xlabel(\"fraud score (mse)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316.269\n",
      "0.476195\n"
     ]
    }
   ],
   "source": [
    "print(np.max(train_batch_mse))\n",
    "print(np.average(train_batch_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#risk = (train_batch_mse - np.average(train_batch_mse))/np.std(train_batch_mse)\n",
    "#risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "output = pd.DataFrame()\n",
    "output['Doctor Identifier'] = df['Doctor Identifier'].values[:18000]\n",
    "output['Risk'] = train_batch_mse[:18000]\n",
    "output.to_csv(\"outputs/autoencoder.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
